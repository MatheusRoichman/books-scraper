# Python Scraper

An **async web scraper** built with **httpx** and **selectolax**, focused on clean architecture,
robust pagination handling, and maintainable parsing logic.

This project scrapes product data from paginated pages, parses HTML efficiently, and saves
structured results to JSON.

---

## âœ¨ Features

- âš¡ **Async HTTP requests** with controlled concurrency
- ğŸ§  **Fast HTML parsing** using Selectolax
- ğŸ“„ **Automatic pagination discovery**
- ğŸ’° **Safe money handling** using `Decimal`
- ğŸ§± **Clean project structure** (parser, pagination, storage, HTTP client)
- ğŸ“¦ **JSON output** with UTF-8 support
- ğŸ§ª Sonar-friendly, low cognitive complexity parsing logic

---

## ğŸ“‹ Requirements

- **Python 3.10+**
- macOS, Linux, or Windows

---

## ğŸš€ Setup

### 1ï¸âƒ£ Create and activate a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run the scraper

```bash
python -m scraper.main
```

After execution:
- Products are scraped from all pages
- Results are saved to the `responses/` directory as JSON

---

## ğŸ“ Project Structure

```
python-scraper/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py        # program entry point
â”‚   â”œâ”€â”€ runner.py      # orchestration logic
â”‚   â”œâ”€â”€ product.py     # Product data model
â”‚   â”œâ”€â”€ parser.py      # HTML â†’ Product parsing
â”‚   â”œâ”€â”€ pagination.py  # pagination discovery
â”‚   â”œâ”€â”€ http_client.py # async HTTP logic
â”‚   â””â”€â”€ storage.py     # JSON persistence
â”‚
â””â”€â”€ responses/          # scraped output
```

---

## ğŸ§  Design Decisions

- **Async-first**: Network I/O is the bottleneck, so async provides major speed gains.
- **Separation of concerns**:
  - HTTP fetching
  - HTML parsing
  - Pagination
  - Persistence
- **No recursion for pagination**: Safer and easier to reason about.
- **Decimal for prices**: Avoids floating-point precision issues.
- **Human-readable JSON**: UTF-8 output with indentation.

---

## ğŸ” Example Output

```json
{
  "title": "A Light in the Attic",
  "price": "45.17",
  "currency": "GBP",
  "availability": "In stock",
  "rating": 3,
  "image_url": "...",
  "details_url": "..."
}
```

---

## âš ï¸ Notes

- Concurrency is limited to avoid stressing the target website.
- Pagination is discovered dynamically from the first page.
- Parsing logic is defensive against missing or malformed HTML.

---

## ğŸ› ï¸ Development

Recommended tools:

```bash
pip install black ruff mypy
```

Format and lint:
```bash
black .
ruff check .
```

---

## ğŸ—ºï¸ Possible Extensions

- CSV or SQLite export
- Retry & exponential backoff
- Progress logging (Page X / Y)
- Deduplication by product URL
- Unit tests for parser helpers
- CLI arguments (concurrency, output path)

---

## ğŸ“„ License

MIT
